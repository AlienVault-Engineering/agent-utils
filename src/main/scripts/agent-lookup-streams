#!/usr/bin/env python3

import botocore.errorfactory
import boto3
import optparse
import os
import functools
import json
import sys
import time

import gimme_aws_creds.main
import gimme_aws_creds.ui


cache_file = '/tmp/agent_lookup_customers.cache'
cache = {}


parser = optparse.OptionParser()
parser.add_option('--infile', '-i', help="file with list of control node streams, one per line")
parser.add_option('--outfile', '-o', default='-', help="output file with results in CSV format (defaults to stdout)")
parser.add_option('--regions', '-r', help="list of regions separted by commas (default all)")
parser.add_option('--streams', '-s', help="list of streams separated by commas (default all)")
parser.add_option('--customers', '-c', help="list of customer name fragments separated by commas (default all)")
parser.add_option('--tags', '-t', help="list of desired output tags separated by commas (default all)")
options, args = parser.parse_args()

profile = 'saas-OktaFirstResponder'
roles = '/{}/'.format(profile)
ui = gimme_aws_creds.ui.CLIUserInterface(argv=[sys.argv[0], '--roles', roles])
creds = gimme_aws_creds.main.GimmeAWSCreds(ui=ui)


# Generate credentials overriding profile name with `okta-<account_id>`
new_profile = None
for data in creds.iter_selected_aws_credentials():
    arn = data['role']['arn']
    account_id = None
    for piece in arn.split(':'):
        if len(piece) == 12 and piece.isdigit():
            account_id = piece
            break

    if account_id is None:
        raise ValueError("Didn't find aws_account_id (12 digits) in {}".format(arn))

    new_profile = 'okta-{}'.format(account_id)
    data['profile']['name'] = new_profile
    creds.write_aws_creds_from_data(data)

session = boto3.session.Session(profile_name=new_profile)

regions = options.regions.split(',') if options.regions else [
    'us-east-1', 'us-west-2',
    'ap-northeast-1', 'ap-northeast-2', 'ap-south-1', 'ap-southeast-1', 'ap-southeast-2',
    'ca-central-1', 'sa-east-1','eu-west-1', 'eu-central-1', 'eu-west-2',
]


in_tags = options.tags.split(',') if options.tags else ['Customer', 'Instance', 'Department', 'Owner']


def load_cache():
    global cache
    if os.path.exists(cache_file):
        cache = json.load(open(cache_file))


def save_cache():
    sys.stderr.write("saving\n")
    with open(cache_file, 'w') as f:
        json.dump(cache, f, indent=2)


save_count = 0
def cache_lookup_stream(stream):
    global save_count
    if stream not in cache:
        save_count += 1
        cache[stream] = tags_for_stream(client, stream)

        if save_count % 20 == 0:
            save_cache()

    return cache[stream]


def backoff(fn):
    @functools.wraps(fn)
    def wrapper(*args, **kwargs):
        for i in range(5):
            try:
                return fn(*args, **kwargs)
            except Exception:
                sys.stderr.write(f"Exceeded limit in {fn.__name__}, sleeping {i+1}\n")
                time.sleep(i+1)

        raise Exception(f"Ran out of retries for {fn.__name__}")

    return wrapper

@backoff
def tags_for_stream(client, stream):
    r = client.list_tags_for_stream(StreamName=stream)
    return {el['Key']: el['Value'] for el in r['Tags']}


@backoff
def fetch_streams(last=None):
    if last:
        return client.list_streams(Limit=500, ExclusiveStartStreamName=last)
    else:
        return client.list_streams(Limit=500)


def streams(client):
    last = None
    while True:
        r = fetch_streams(last)
        for s in r['StreamNames']:
            yield s
            last = s

        if not r['HasMoreStreams']:
            break


if __name__ == '__main__':
    load_cache()

    instreams = []
    incusts = []

    if options.infile:
        close = False
        if options.infile == '-':
            f = sys.stdin
        else:
            close = True
            f = open(options.infile)

        instreams = []
        for line in f:
            line2 = line.split()
            if not line2:
                print('???', line,line2)
                continue

            instreams.append(line2[0])

        if close:
            f.close()

    outf = sys.stdout
    if options.outfile:
        if options.outfile != '-':
            outf = open(options.outfile, 'w')

    if options.streams:
        instreams.extend([x.strip() for x in options.streams.split(',')])

    if options.customers:
        incusts.extend([x.strip() for x in options.customers.split(',')])

    instreams = set(instreams)
    incusts = set(incusts)

    has_streams = bool(instreams)
    has_custs = bool(incusts)

    outf.write(f"stream,region,{','.join(in_tags)}\n")
    count = 0
    for region in regions:
        sys.stderr.write(f"--------------------- {region}\n")

        client = session.client('kinesis', region_name=region)
        for stream in streams(client):
            cust_match = False
            if has_custs:
                tags = cache_lookup_stream(stream)

                for c in incusts:
                    for t in tags.values():
                        if c in t:
                            cust_match = c
                            break

                    if cust_match:
                        break

            if (not has_streams and not has_custs) or stream in instreams or cust_match:
                if not has_custs:
                    tags = cache_lookup_stream(stream)

                sys.stderr.write(f"found {stream}\n")
                outf.write(f"{stream},{region},{','.join([str(tags.get(t, 'MISSING')) for t in in_tags])}\n")
                outf.flush()
                if instreams:
                    instreams.remove(stream)

                # if incusts and cust_match:
                #     incusts.remove(cust_match)

    for stream in instreams:
        outf.write(f"{stream},{','.join(['MISSING']*len(in_tags))}\n")

    # for cust in incusts:
    #     outf.write(f"customer={cust},{['MISSING']*len(tags)}\n")

    outf.flush()
    outf.close()

    save_cache()

